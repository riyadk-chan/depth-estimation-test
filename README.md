# Depth Estimation 

> Exploration d'une premi√®re approche pour l'estimation de profondeur monoculaire sur images en niveaux de gris  


[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com)

---

## Objectif

√âvaluer la pertinence de **DepthAnything V2** pour l'estimation de profondeur sur images. Les principaux r√©seaux de neuronnes √©tant entrain√©s sur des images en couleur (**RBG**) tester les performances pour les images en niveau de gris (**grayscale**). 


---

##  R√©sultats

![Comparaison RGB vs Grayscale](images/depth_test.png)(images/depth_test2.png)

Voir le notebook complet dans `demo.ipynb` pour reproduire les r√©sultats.

### Observations Cl√©s

 **Ce qui fonctionne bien :**
- Estimation coh√©rente sur images RGB et grayscale
- Temps de traitement acceptable (~0.4s sur GPU T4)
- Segmentation claire premier plan / arri√®re-plan
- Duplication du canal semble effective : diff√©rence n√©gligeable entre RGB et grayscale
- Grayscale l√©g√®rement plus rapide (~20% de gain)


 **Limitations identifi√©es :**
- Profondeur **relative** uniquement (pas de distances m√©triques)
- Surfaces uniformes moins bien d√©tect√©es
- Tests limit√©s √† seulement 2 images (manque de temps)

 **Pistes d'am√©lioration :**
- Calibration m√©trique avec profilom√®tre comme ground truth pour obtenir la profondeur **absolue**
- Fine-tuning sur images sp√©cifiques
- Tests de robustesse (√©clairage, angles, surfaces)
- Optimisation pour d√©ploiement temps r√©el 



---




## Technologies Utilis√©es

- **DepthAnything V2 Base** : Mod√®le state-of-the-art pour estimation de profondeur
- **PyTorch 2.0+** : Framework deep learning
- **Transformers (HuggingFace)** : Pipeline simplifi√© pour l'inf√©rence
- **Google Colab** : Environnement de d√©veloppement avec GPU gratuit

---

## Contexte Technique

Les cam√©ras lin√©aires industrielles capturent en **niveaux de gris** pour :
- Vitesse d'acquisition sup√©rieure
- Simplicit√© du traitement
- R√©duction des donn√©es/co√ªts

Le d√©fi est donc d'adapter les mod√®les d'IA (entra√Æn√©s sur RGB) pour fonctionner sur ces images grayscale.

### Approche Utilis√©e ici 

**Conversion grayscale ‚Üí RGB en dupliquant le canal 3 fois :**
```python
gray_image = image.convert('L')  # Conversion en grayscale
gray_np = np.array(gray_image)
rgb_np = np.stack([gray_np, gray_np, gray_np], axis=-1)  # Duplication du canal
```

Cette m√©thode simple permet de conserver la compatibilit√© avec les mod√®les pr√©-entra√Æn√©s RGB.


## üìñ Ressources

- **DepthAnything V2 Paper** : [Depth Anything V2](https://arxiv.org/abs/2406.09414)
- **GitHub officiel** : [DepthAnything/Depth-Anything-V2](https://github.com/DepthAnything/Depth-Anything-V2)
- **HuggingFace** : [depth-anything/Depth-Anything-V2-Base-hf](https://huggingface.co/depth-anything/Depth-Anything-V2-Base-hf)
- **Documentation PyTorch** : [pytorch.org](https://pytorch.org/docs/stable/index.html)

---

## üìÅ Structure du Projet

```
depth-estimation-michelin-demo/
‚îú‚îÄ‚îÄ README.md                    # Ce fichier
‚îú‚îÄ‚îÄ demo.ipynb                   # Notebook Colab complet
‚îú‚îÄ‚îÄ requirements.txt             # D√©pendances
‚îî‚îÄ‚îÄ images/
    ‚îî‚îÄ‚îÄ results_comparison.png  # R√©sultats visuels
```

---

## ü§ù Contribution

Ce projet est une exploration personnelle dans le cadre d'une candidature de stage. Les suggestions et retours sont les bienvenus !

---

## üë§ Contact

**[Riyad Khichane]**  
üìß Email : [riyad.khichane@gmail.com]  

---

## üìÑ License

Ce projet est √† usage √©ducatif et de d√©monstration. Le mod√®le DepthAnything V2 est sous licence Apache 2.0.

---

<p align="center">
  <i>D√©velopp√© avec passion pour l'innovation en vision industrielle </i>
</p>

